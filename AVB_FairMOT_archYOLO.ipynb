{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"gpuClass":"standard"},"cells":[{"cell_type":"code","metadata":{"id":"aUAr2X8O_7SI"},"source":["!git clone https://github.com/NS19972/FairMOT.git\n","print ('\\n\\n######___CLONE_is_OK___######\\n')\n","\n","!pip install torch==1.7.1 \n","print ('\\n\\n######___Torch_installing___######\\n')\n","\n","!pip install torchvision==0.8.2 \n","print ('\\n\\n######___Torchvision_installing___######\\n')"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WiiGb66TqGek","outputId":"d7ac7446-46ec-40fd-ca23-8cb8c2360bd7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"yabO2wjF-_wi"},"source":["%cd FairMOT\n","# переходим в директорию FairMOT\n","\n","!pip install -r requirements.txt\n","# Установка зависимостей \n","\n","!git clone -b pytorch_1.7 https://github.com/ifzhang/DCNv2.git\n","# Зависимости библиотеки pytorch_1.7 в директорию DCNv2\n","\n","%cd DCNv2\n","# переходим в директорию DCNv2\n","\n","!./make.sh\n","# Монтируем (собираем) pyTorch1.7 в директории DCNv2\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XDX7g3jwk8SB"},"source":["# переходим в директорию\n","%cd /content/FairMOT\n","\n","# устанавливаем gdown и обновляем\n","!pip install -U --no-cache-dir gdown --pre\n","!pip install --upgrade --no-cache-dir gdown\n","\n","# в какой директории находимся?\n","%cd ..\n","\n","# загружаем в корневой каталог /content/ предобученные веса\n","!gdown --no-cookies https://drive.google.com/u/0/uc?id=1HVzDTrYSSZiVqExqG9rou3zZXX1-GGQn&export=download\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# gen_labels_train\n","!gdown --no-cookies --fuzzy https://drive.google.com/file/d/1rSXThzmy2iLgMVADN2PombM73FKmqiOW/view?usp=share_link&export=download\n","\n","# gen_labels_val \n","!gdown --no-cookies --fuzzy https://drive.google.com/file/d/1Sw3uioZ8jly9LZuCdsFkmZAneZu-_N2i/view?usp=share_link&export=download\n","\n","# images\n","!gdown --no-cookies --fuzzy https://drive.google.com/file/d/1DSdf58mJLN9UBESY7ikdXTiZpuRb1O8y/view?usp=share_link&export=download"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uNk5dKcwq3h7","outputId":"24f1a7c1-5b2e-4b8a-d3e3-6461f608f75d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading...\n","From: https://drive.google.com/uc?id=1rSXThzmy2iLgMVADN2PombM73FKmqiOW\n","To: /content/gen_labels_train.zip\n","100% 807k/807k [00:00<00:00, 101MB/s]\n","Downloading...\n","From: https://drive.google.com/uc?id=1Sw3uioZ8jly9LZuCdsFkmZAneZu-_N2i\n","To: /content/gen_labels_val.zip\n","100% 148k/148k [00:00<00:00, 77.8MB/s]\n","Downloading...\n","From: https://drive.google.com/uc?id=1DSdf58mJLN9UBESY7ikdXTiZpuRb1O8y\n","To: /content/images.zip\n","100% 484M/484M [00:05<00:00, 82.1MB/s]\n"]}]},{"cell_type":"code","metadata":{"id":"WThb4sK2Cs5E","outputId":"ccadbd7b-83eb-4ac0-92bc-5d3ab405dc64","colab":{"base_uri":"https://localhost:8080/","height":72}},"source":["'''\n","#loading training data\n","!gdown --no-cookies https://drive.google.com/u/0/uc?id=134QOvaatwKdy0iIeNqA_p-xkAhkV4F8Y\n","#loading validation data\n","!gdown --no-cookies https://drive.google.com/u/0/uc?id=18jFI789CoHTppQ7vmRSFEdnGaSQZ4YzO&export=download\n","#loading annotation_train\n","!gdown --no-cookies  https://drive.google.com/u/0/uc?id=1UUTea5mYqvlUObsC1Z8CFldHJAtLtMX3&export=download\n","#loading annotation_val\n","!gdown --no-cookies  https://drive.google.com/u/0/uc?id=10WIRwu8ju8GRLuCkZ_vT6hnNxs5ptwoL&export=download\n","'''"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\n#loading training data\\n!gdown --no-cookies https://drive.google.com/u/0/uc?id=134QOvaatwKdy0iIeNqA_p-xkAhkV4F8Y\\n#loading validation data\\n!gdown --no-cookies https://drive.google.com/u/0/uc?id=18jFI789CoHTppQ7vmRSFEdnGaSQZ4YzO&export=download\\n#loading annotation_train\\n!gdown --no-cookies  https://drive.google.com/u/0/uc?id=1UUTea5mYqvlUObsC1Z8CFldHJAtLtMX3&export=download\\n#loading annotation_val\\n!gdown --no-cookies  https://drive.google.com/u/0/uc?id=10WIRwu8ju8GRLuCkZ_vT6hnNxs5ptwoL&export=download\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"pQTcmgkdRnUC"},"source":["\n","%mkdir -p FairMOT/dataset/images/train\n","%mkdir -p FairMOT/dataset/images/val\n","\n","%mkdir -p FairMOT/dataset/labels_with_ids/train\n","%mkdir -p FairMOT/dataset/labels_with_ids/val"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!unzip \"/content/gen_labels_train.zip\" -d \"/content/gen_labels_train\"\n","!unzip \"/content/gen_labels_val.zip\" -d \"/content/gen_labels_val\"\n","!unzip \"/content/images.zip\" -d \"/content/images\""],"metadata":{"id":"L-a3MQ8druaM"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"whsiEX0oXP_H","outputId":"0052875f-35fc-47e4-c03c-b4614c91085b","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["'''\n","!unzip \"/content/CrowdHuman_train01.zip\" -d \"/content/train\"\n","!unzip \"/content/CrowdHuman_val.zip\" -d \"/content/val\"\n","'''"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\n!unzip \"/content/CrowdHuman_train01.zip\" -d \"/content/train\"\\n!unzip \"/content/CrowdHuman_val.zip\" -d \"/content/val\"\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":10}]},{"cell_type":"markdown","source":["**Сверим лейблы и картинки**\n"],"metadata":{"id":"HFZ4uBLtSrbv"}},{"cell_type":"code","metadata":{"id":"e3HuEcxmXdqR","outputId":"ad960e07-70b7-4bf8-f872-a41f6e0880ca","colab":{"base_uri":"https://localhost:8080/"}},"source":["# Копируем картинки в директорию МОТ\n","%cp /content/images/images/train/* /content/FairMOT/dataset/images/train\n","%cp /content/images/images/val/*   /content/FairMOT/dataset/images/val\n","print ('copy is OK')\n","#%cp /content/annotation_train.odgt /content/FairMOT/dataset/annotation_train.odgt\n","#%cp /content/annotation_val.odgt   /content/FairMOT/dataset/annotation_val.odgt"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["copy is OK\n"]}]},{"cell_type":"code","source":["# Копируем лейблы в директорию МОТ\n","%cp /content/gen_labels_train/gen_labels_train/* /content/FairMOT/dataset/labels_with_ids/train\n","%cp /content/gen_labels_val/gen_labels_val/*   /content/FairMOT/dataset/labels_with_ids/val\n","print ('copy is OK')\n"],"metadata":{"id":"e2AD3m5WtJ7R","outputId":"aa838f4f-81ab-4c83-b255-8f9f79ef484b","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["copy is OK\n"]}]},{"cell_type":"code","source":["import os\n","\n","list_img = []\n","\n","for fail_name in os.listdir('/content/FairMOT/dataset/images/train'):\n","  list_img.append(fail_name)\n","unique_list_img = list(set(list_img))\n","print('Количество уникальных имен картинок:',len(unique_list_img))\n","\n","list_labels = []\n","\n","for fail_name in os.listdir('/content/FairMOT/dataset/labels_with_ids/train'):\n","  list_labels.append(fail_name)\n","unique_list_labels = list(set(list_labels))\n","print('Количество уникальных имен лейблов:',len(unique_list_labels))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3lT-N6ynSxyP","outputId":"9ce360cd-f76b-4991-b412-143f9b6aefb4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Количество уникальных имен картинок: 3169\n","Количество уникальных имен лейблов: 3169\n"]}]},{"cell_type":"code","metadata":{"id":"K-mE9ns7ZnhJ","outputId":"9e8adc03-3074-4595-b834-d93371d93058","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["import os\n","import pandas as pd\n","train_dir = '/content/FairMOT/dataset/images/train/'\n","val_dir = '/content/FairMOT/dataset/images/val/'\n","\n","training_files = os.listdir('/content/images/images/train')\n","val_files = os.listdir('/content/images/images/val')\n","\n","training_df = pd.DataFrame(training_files,columns=['images'])\n","training_df.images = training_df.images.map(lambda x: train_dir + x)\n","val_df = pd.DataFrame(val_files,columns=['images'])\n","val_df.images = val_df.images.map(lambda x: val_dir + x)\n","\n","%pwd"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":14}]},{"cell_type":"code","metadata":{"id":"exnx0gfLcDmR","colab":{"base_uri":"https://localhost:8080/"},"outputId":"8feab240-fe27-435c-d76c-e477fd682bcd"},"source":["%cd FairMOT/ "],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/FairMOT\n"]}]},{"cell_type":"code","metadata":{"id":"-plWRr3iXGjz"},"source":["#Generate files containing image paths and save to src/data\n","train_file = 'src/data/crowdhuman.train'\n","test_file = 'src/data/crowdhuman.val'\n","with open(train_file, 'w') as f:\n","    f.write(\"\\n\".join(training_df.images.values))\n","with open(test_file, 'w') as f:\n","    f.write(\"\\n\".join(val_df.images.values))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"C4CkwXw0P5wX"},"source":["#Create a json file for the dataset in src/lib/cfg/\n","import json\n","train_file = 'src/data/crowdhuman.train'\n","test_file  = 'src/data/crowdhuman.val'\n","cfg = dict(\n","    root='/content/FairMOT/dataset',\n","    train=dict(CrowdHuman_train01=train_file,\n","               CrowedHuman_test=test_file),\n","    test=dict(CrowedHuman_test=test_file),\n","    test_emb=dict(CrowedHuman_test=test_file),\n",")\n","with open('src/lib/cfg/crowdhuman.json', 'w') as f:\n","    json.dump(cfg, f, indent=4)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Обучение по 5 эпох**"],"metadata":{"id":"nc-TsqPO93s_"}},{"cell_type":"code","metadata":{"id":"kOO5Rc7xkU9I"},"source":["#!python src/gen_labels_crowd_id.py"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#!python /content/FairMOT/src/train.py mot --arch resdcn_34 --gpus 0   --batch_size 2  --num_epochs 20 --lr_step '50' --data_cfg '/content/FairMOT/src/lib/cfg/crowdhuman.json'\n"],"metadata":{"id":"2jxdsq7QYEcG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","#  --arch 'yolo'\n","!python /content/FairMOT/src/train.py mot --arch 'yolo' --gpus 0 --batch_size 16 --num_epochs 5 --lr_step '50' --data_cfg '/content/FairMOT/src/lib/cfg/crowdhuman.json'\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WQW6E48GrV8C","outputId":"25e85373-841c-49d5-8586-96eb3037096e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Using tensorboardX\n","Fix size testing.\n","training chunk_sizes: [16]\n","The output will be saved to  /content/FairMOT/src/lib/../../exp/mot/default\n","Setting up data...\n","================================================================================\n","dataset summary\n","OrderedDict([('CrowdHuman_train01', 1.0), ('CrowedHuman_test', 1.0)])\n","total # identities: 3\n","start index\n","OrderedDict([('CrowdHuman_train01', 0), ('CrowedHuman_test', 1.0)])\n","================================================================================\n","heads {'hm': 1, 'wh': 4, 'id': 128, 'reg': 2}\n","Namespace(task='mot', dataset='jde', exp_id='default', test=False, load_model='', resume=False, gpus=[0], num_workers=8, not_cuda_benchmark=False, seed=317, print_iter=0, hide_data_time=False, save_all=False, metric='loss', vis_thresh=0.5, arch='yolo', head_conv=256, down_ratio=4, input_res=1088, input_h=1088, input_w=608, lr=0.0001, lr_step=[50], num_epochs=5, batch_size=16, master_batch_size=16, num_iters=-1, val_intervals=5, trainval=False, K=500, not_prefetch_test=False, fix_res=True, keep_res=False, test_mot16=False, val_mot15=False, test_mot15=False, val_mot16=False, test_mot17=False, val_mot17=True, val_mot20=False, test_mot20=False, val_hie=False, test_hie=False, conf_thres=0.4, det_thres=0.3, nms_thres=0.4, track_buffer=30, min_box_area=100, input_video='../videos/MOT16-03.mp4', output_format='video', output_root='../demos', data_cfg='/content/FairMOT/src/lib/cfg/crowdhuman.json', data_dir='/home/zyf/dataset', mse_loss=False, reg_loss='l1', hm_weight=1, off_weight=1, wh_weight=0.1, id_loss='ce', id_weight=1, reid_dim=128, ltrb=True, multi_loss='uncertainty', norm_wh=False, dense_wh=False, cat_spec_wh=False, not_reg_offset=False, gpus_str='0', reg_offset=True, pad=31, num_stacks=1, chunk_sizes=[16], root_dir='/content/FairMOT/src/lib/../..', exp_dir='/content/FairMOT/src/lib/../../exp/mot', save_dir='/content/FairMOT/src/lib/../../exp/mot/default', debug_dir='/content/FairMOT/src/lib/../../exp/mot/default/debug', mean=None, std=None, num_classes=1, output_h=272, output_w=152, output_res=272, heads={'hm': 1, 'wh': 4, 'id': 128, 'reg': 2}, nID=3, img_size=(1088, 608))\n","Creating model...\n","/content/FairMOT/src/lib/models/networks/config/yolov5s.yaml\n","Starting training...\n","/usr/local/lib/python3.9/dist-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n","  warnings.warn(warning.format(ret))\n","mot/default |################################| train: [1][235/236]|Tot: 0:04:37 |ETA: 0:00:02 |loss 25.9028 |hm_loss 6.4716 |wh_loss 15.3785 |off_loss 0.3192 |id_loss 0.6910 |Data 0.001s(0.165s) |Net 1.174s   \n","mot/default |################################| train: [2][235/236]|Tot: 0:04:39 |ETA: 0:00:01 |loss 8.8563 |hm_loss 2.3691 |wh_loss 3.9528 |off_loss 0.2577 |id_loss 0.5875 |Data 0.001s(0.220s) |Net 1.185s  \n","mot/default |################################| train: [3][235/236]|Tot: 0:04:43 |ETA: 0:00:01 |loss 7.1476 |hm_loss 1.9296 |wh_loss 3.3801 |off_loss 0.2546 |id_loss 0.5313 |Data 0.001s(0.228s) |Net 1.199s \n","mot/default |################################| train: [4][235/236]|Tot: 0:04:39 |ETA: 0:00:01 |loss 5.9682 |hm_loss 1.6148 |wh_loss 3.0880 |off_loss 0.2519 |id_loss 0.4981 |Data 0.001s(0.206s) |Net 1.185s\n","mot/default |################################| train: [5][235/236]|Tot: 0:04:40 |ETA: 0:00:02 |loss 5.2344 |hm_loss 1.4163 |wh_loss 2.9644 |off_loss 0.2504 |id_loss 0.4773 |Data 0.001s(0.204s) |Net 1.189s \n","\u001b[?25h"]}]},{"cell_type":"code","source":["\n","# Дообучаем 5+ 5epoch\n","!python /content/FairMOT/src/train.py mot --arch 'yolo' --gpus 0 --load_model /content/FairMOT/exp/mot/default/model_last.pth  --batch_size 16  --num_epochs 5 --lr_step '50' --data_cfg '/content/FairMOT/src/lib/cfg/crowdhuman.json'\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TMhKu188lnWM","outputId":"f2cb0984-e27b-42f3-cd2c-0a446bc0bed3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Using tensorboardX\n","Fix size testing.\n","training chunk_sizes: [16]\n","The output will be saved to  /content/FairMOT/src/lib/../../exp/mot/default\n","Setting up data...\n","================================================================================\n","dataset summary\n","OrderedDict([('CrowdHuman_train01', 1.0), ('CrowedHuman_test', 1.0)])\n","total # identities: 3\n","start index\n","OrderedDict([('CrowdHuman_train01', 0), ('CrowedHuman_test', 1.0)])\n","================================================================================\n","heads {'hm': 1, 'wh': 4, 'id': 128, 'reg': 2}\n","Namespace(task='mot', dataset='jde', exp_id='default', test=False, load_model='/content/FairMOT/exp/mot/default/model_last.pth', resume=False, gpus=[0], num_workers=8, not_cuda_benchmark=False, seed=317, print_iter=0, hide_data_time=False, save_all=False, metric='loss', vis_thresh=0.5, arch='yolo', head_conv=256, down_ratio=4, input_res=1088, input_h=1088, input_w=608, lr=0.0001, lr_step=[50], num_epochs=5, batch_size=16, master_batch_size=16, num_iters=-1, val_intervals=5, trainval=False, K=500, not_prefetch_test=False, fix_res=True, keep_res=False, test_mot16=False, val_mot15=False, test_mot15=False, val_mot16=False, test_mot17=False, val_mot17=True, val_mot20=False, test_mot20=False, val_hie=False, test_hie=False, conf_thres=0.4, det_thres=0.3, nms_thres=0.4, track_buffer=30, min_box_area=100, input_video='../videos/MOT16-03.mp4', output_format='video', output_root='../demos', data_cfg='/content/FairMOT/src/lib/cfg/crowdhuman.json', data_dir='/home/zyf/dataset', mse_loss=False, reg_loss='l1', hm_weight=1, off_weight=1, wh_weight=0.1, id_loss='ce', id_weight=1, reid_dim=128, ltrb=True, multi_loss='uncertainty', norm_wh=False, dense_wh=False, cat_spec_wh=False, not_reg_offset=False, gpus_str='0', reg_offset=True, pad=31, num_stacks=1, chunk_sizes=[16], root_dir='/content/FairMOT/src/lib/../..', exp_dir='/content/FairMOT/src/lib/../../exp/mot', save_dir='/content/FairMOT/src/lib/../../exp/mot/default', debug_dir='/content/FairMOT/src/lib/../../exp/mot/default/debug', mean=None, std=None, num_classes=1, output_h=272, output_w=152, output_res=272, heads={'hm': 1, 'wh': 4, 'id': 128, 'reg': 2}, nID=3, img_size=(1088, 608))\n","Creating model...\n","/content/FairMOT/src/lib/models/networks/config/yolov5s.yaml\n","Starting training...\n","loaded /content/FairMOT/exp/mot/default/model_last.pth, epoch 5\n","/usr/local/lib/python3.9/dist-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n","  warnings.warn(warning.format(ret))\n","mot/default |################################| train: [1][235/236]|Tot: 0:04:44 |ETA: 0:00:01 |loss 5.2850 |hm_loss 1.2848 |wh_loss 2.9418 |off_loss 0.2518 |id_loss 0.6838 |Data 0.001s(0.198s) |Net 1.204s \n","mot/default |################################| train: [2][235/236]|Tot: 0:04:39 |ETA: 0:00:01 |loss 4.5213 |hm_loss 1.1323 |wh_loss 2.8439 |off_loss 0.2503 |id_loss 0.5853 |Data 0.001s(0.205s) |Net 1.186s\n","mot/default |################################| train: [3][235/236]|Tot: 0:04:38 |ETA: 0:00:01 |loss 4.0721 |hm_loss 1.0481 |wh_loss 2.7966 |off_loss 0.2495 |id_loss 0.5286 |Data 0.001s(0.204s) |Net 1.179s\n","mot/default |################################| train: [4][235/236]|Tot: 0:04:35 |ETA: 0:00:01 |loss 3.5163 |hm_loss 0.9198 |wh_loss 2.7160 |off_loss 0.2463 |id_loss 0.4869 |Data 0.001s(0.183s) |Net 1.169s\n","mot/default |################################| train: [5][235/236]|Tot: 0:04:36 |ETA: 0:00:01 |loss 3.2104 |hm_loss 0.8557 |wh_loss 2.6760 |off_loss 0.2449 |id_loss 0.4632 |Data 0.001s(0.176s) |Net 1.170s\n","\u001b[?25h"]}]},{"cell_type":"code","source":["\n","# Дообучаем 10+ 10epoch\n","!python /content/FairMOT/src/train.py mot --arch 'yolo' --gpus 0 --load_model /content/FairMOT/exp/mot/default/model_last.pth  --batch_size 16  --num_epochs 10 --lr_step '50' --data_cfg '/content/FairMOT/src/lib/cfg/crowdhuman.json'\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t-OWd7fzlnTh","outputId":"b838cc96-086a-4bd9-a7c5-aabcbdacc42c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Using tensorboardX\n","Fix size testing.\n","training chunk_sizes: [16]\n","The output will be saved to  /content/FairMOT/src/lib/../../exp/mot/default\n","Setting up data...\n","================================================================================\n","dataset summary\n","OrderedDict([('CrowdHuman_train01', 1.0), ('CrowedHuman_test', 1.0)])\n","total # identities: 3\n","start index\n","OrderedDict([('CrowdHuman_train01', 0), ('CrowedHuman_test', 1.0)])\n","================================================================================\n","heads {'hm': 1, 'wh': 4, 'id': 128, 'reg': 2}\n","Namespace(task='mot', dataset='jde', exp_id='default', test=False, load_model='/content/FairMOT/exp/mot/default/model_last.pth', resume=False, gpus=[0], num_workers=8, not_cuda_benchmark=False, seed=317, print_iter=0, hide_data_time=False, save_all=False, metric='loss', vis_thresh=0.5, arch='yolo', head_conv=256, down_ratio=4, input_res=1088, input_h=1088, input_w=608, lr=0.0001, lr_step=[50], num_epochs=10, batch_size=16, master_batch_size=16, num_iters=-1, val_intervals=5, trainval=False, K=500, not_prefetch_test=False, fix_res=True, keep_res=False, test_mot16=False, val_mot15=False, test_mot15=False, val_mot16=False, test_mot17=False, val_mot17=True, val_mot20=False, test_mot20=False, val_hie=False, test_hie=False, conf_thres=0.4, det_thres=0.3, nms_thres=0.4, track_buffer=30, min_box_area=100, input_video='../videos/MOT16-03.mp4', output_format='video', output_root='../demos', data_cfg='/content/FairMOT/src/lib/cfg/crowdhuman.json', data_dir='/home/zyf/dataset', mse_loss=False, reg_loss='l1', hm_weight=1, off_weight=1, wh_weight=0.1, id_loss='ce', id_weight=1, reid_dim=128, ltrb=True, multi_loss='uncertainty', norm_wh=False, dense_wh=False, cat_spec_wh=False, not_reg_offset=False, gpus_str='0', reg_offset=True, pad=31, num_stacks=1, chunk_sizes=[16], root_dir='/content/FairMOT/src/lib/../..', exp_dir='/content/FairMOT/src/lib/../../exp/mot', save_dir='/content/FairMOT/src/lib/../../exp/mot/default', debug_dir='/content/FairMOT/src/lib/../../exp/mot/default/debug', mean=None, std=None, num_classes=1, output_h=272, output_w=152, output_res=272, heads={'hm': 1, 'wh': 4, 'id': 128, 'reg': 2}, nID=3, img_size=(1088, 608))\n","Creating model...\n","/content/FairMOT/src/lib/models/networks/config/yolov5s.yaml\n","Starting training...\n","loaded /content/FairMOT/exp/mot/default/model_last.pth, epoch 5\n","/usr/local/lib/python3.9/dist-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n","  warnings.warn(warning.format(ret))\n","mot/default |################################| train: [1][235/236]|Tot: 0:04:39 |ETA: 0:00:01 |loss 3.7009 |hm_loss 0.8196 |wh_loss 2.6491 |off_loss 0.2461 |id_loss 0.6753 |Data 0.001s(0.189s) |Net 1.184s \n","mot/default |################################| train: [2][235/236]|Tot: 0:04:43 |ETA: 0:00:01 |loss 3.2024 |hm_loss 0.7505 |wh_loss 2.4948 |off_loss 0.2448 |id_loss 0.5704 |Data 0.001s(0.242s) |Net 1.199s \n","mot/default |################################| train: [3][235/236]|Tot: 0:04:40 |ETA: 0:00:01 |loss 2.7874 |hm_loss 0.6913 |wh_loss 2.2412 |off_loss 0.2442 |id_loss 0.5085 |Data 0.001s(0.211s) |Net 1.189s\n","mot/default |################################| train: [4][235/236]|Tot: 0:04:43 |ETA: 0:00:01 |loss 2.3892 |hm_loss 0.6300 |wh_loss 1.9372 |off_loss 0.2432 |id_loss 0.4616 |Data 0.001s(0.233s) |Net 1.199s\n","mot/default |################################| train: [5][235/236]|Tot: 0:04:43 |ETA: 0:00:01 |loss 2.1885 |hm_loss 0.5954 |wh_loss 1.8704 |off_loss 0.2408 |id_loss 0.4449 |Data 0.002s(0.228s) |Net 1.202s \n","mot/default |################################| train: [6][235/236]|Tot: 0:04:40 |ETA: 0:00:01 |loss 2.2897 |hm_loss 0.6634 |wh_loss 1.8062 |off_loss 0.2418 |id_loss 0.4245 |Data 0.001s(0.221s) |Net 1.190s\n","mot/default |################################| train: [7][235/236]|Tot: 0:04:46 |ETA: 0:00:01 |loss 2.0562 |hm_loss 0.6205 |wh_loss 1.7076 |off_loss 0.2391 |id_loss 0.4041 |Data 0.001s(0.240s) |Net 1.212s\n","mot/default |################################| train: [8][235/236]|Tot: 0:05:07 |ETA: 0:00:01 |loss 1.9191 |hm_loss 0.5950 |wh_loss 1.6513 |off_loss 0.2408 |id_loss 0.3960 |Data 0.001s(0.317s) |Net 1.303s \n","mot/default |################################| train: [9][235/236]|Tot: 0:04:52 |ETA: 0:00:01 |loss 1.7966 |hm_loss 0.5820 |wh_loss 1.6359 |off_loss 0.2388 |id_loss 0.3692 |Data 0.001s(0.253s) |Net 1.239s\n","mot/default |################################| train: [10][235/236]|Tot: 0:05:13 |ETA: 0:00:01 |loss 1.6485 |hm_loss 0.5555 |wh_loss 1.5853 |off_loss 0.2373 |id_loss 0.3535 |Data 0.001s(0.330s) |Net 1.327s \n","\u001b[?25h"]}]},{"cell_type":"code","source":["\n","# Дообучаем 20+ 5epoch batch_size_12\n","!python /content/FairMOT/src/train.py mot --arch 'yolo' --gpus 0 --load_model /content/FairMOT/exp/mot/default/model_last.pth  --batch_size 12  --num_epochs 5 --lr_step '50' --data_cfg '/content/FairMOT/src/lib/cfg/crowdhuman.json'\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4cj4Ul0dlnQZ","outputId":"4f17b1d9-8fdd-437d-a262-97a2fdf7a14e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Using tensorboardX\n","Fix size testing.\n","training chunk_sizes: [12]\n","The output will be saved to  /content/FairMOT/src/lib/../../exp/mot/default\n","Setting up data...\n","================================================================================\n","dataset summary\n","OrderedDict([('CrowdHuman_train01', 1.0), ('CrowedHuman_test', 1.0)])\n","total # identities: 3\n","start index\n","OrderedDict([('CrowdHuman_train01', 0), ('CrowedHuman_test', 1.0)])\n","================================================================================\n","heads {'hm': 1, 'wh': 4, 'id': 128, 'reg': 2}\n","Namespace(task='mot', dataset='jde', exp_id='default', test=False, load_model='/content/FairMOT/exp/mot/default/model_last.pth', resume=False, gpus=[0], num_workers=8, not_cuda_benchmark=False, seed=317, print_iter=0, hide_data_time=False, save_all=False, metric='loss', vis_thresh=0.5, arch='yolo', head_conv=256, down_ratio=4, input_res=1088, input_h=1088, input_w=608, lr=0.0001, lr_step=[50], num_epochs=5, batch_size=12, master_batch_size=12, num_iters=-1, val_intervals=5, trainval=False, K=500, not_prefetch_test=False, fix_res=True, keep_res=False, test_mot16=False, val_mot15=False, test_mot15=False, val_mot16=False, test_mot17=False, val_mot17=True, val_mot20=False, test_mot20=False, val_hie=False, test_hie=False, conf_thres=0.4, det_thres=0.3, nms_thres=0.4, track_buffer=30, min_box_area=100, input_video='../videos/MOT16-03.mp4', output_format='video', output_root='../demos', data_cfg='/content/FairMOT/src/lib/cfg/crowdhuman.json', data_dir='/home/zyf/dataset', mse_loss=False, reg_loss='l1', hm_weight=1, off_weight=1, wh_weight=0.1, id_loss='ce', id_weight=1, reid_dim=128, ltrb=True, multi_loss='uncertainty', norm_wh=False, dense_wh=False, cat_spec_wh=False, not_reg_offset=False, gpus_str='0', reg_offset=True, pad=31, num_stacks=1, chunk_sizes=[12], root_dir='/content/FairMOT/src/lib/../..', exp_dir='/content/FairMOT/src/lib/../../exp/mot', save_dir='/content/FairMOT/src/lib/../../exp/mot/default', debug_dir='/content/FairMOT/src/lib/../../exp/mot/default/debug', mean=None, std=None, num_classes=1, output_h=272, output_w=152, output_res=272, heads={'hm': 1, 'wh': 4, 'id': 128, 'reg': 2}, nID=3, img_size=(1088, 608))\n","Creating model...\n","/content/FairMOT/src/lib/models/networks/config/yolov5s.yaml\n","Starting training...\n","loaded /content/FairMOT/exp/mot/default/model_last.pth, epoch 10\n","/usr/local/lib/python3.9/dist-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n","  warnings.warn(warning.format(ret))\n","mot/default |################################| train: [1][313/314]|Tot: 0:05:11 |ETA: 0:00:01 |loss 2.5729 |hm_loss 0.5858 |wh_loss 1.6421 |off_loss 0.2401 |id_loss 0.6428 |Data 0.001s(0.125s) |Net 0.992s\n","mot/default |################################| train: [2][313/314]|Tot: 0:05:09 |ETA: 0:00:01 |loss 2.1972 |hm_loss 0.5550 |wh_loss 1.5751 |off_loss 0.2386 |id_loss 0.5170 |Data 0.001s(0.138s) |Net 0.986s\n","mot/default |################################| train: [3][313/314]|Tot: 0:05:10 |ETA: 0:00:01 |loss 1.9726 |hm_loss 0.5380 |wh_loss 1.5614 |off_loss 0.2390 |id_loss 0.4427 |Data 0.001s(0.123s) |Net 0.989s\n","mot/default |################################| train: [4][313/314]|Tot: 0:05:11 |ETA: 0:00:01 |loss 1.7799 |hm_loss 0.5168 |wh_loss 1.5144 |off_loss 0.2404 |id_loss 0.3985 |Data 0.001s(0.139s) |Net 0.993s\n","mot/default |################################| train: [5][313/314]|Tot: 0:05:04 |ETA: 0:00:01 |loss 1.5865 |hm_loss 0.4851 |wh_loss 1.4972 |off_loss 0.2381 |id_loss 0.3710 |Data 0.001s(0.126s) |Net 0.969s \n","\u001b[?25h"]}]},{"cell_type":"code","source":["\n","# Дообучаем 25+ 10epoch\n","!python /content/FairMOT/src/train.py mot --arch 'yolo' --gpus 0 --load_model /content/FairMOT/exp/mot/default/model_last.pth  --batch_size 16  --num_epochs 10 --lr_step '50' --data_cfg '/content/FairMOT/src/lib/cfg/crowdhuman.json'\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A3SMqIwolnDq","outputId":"9ff40fc2-e0bb-4cd5-bc34-299c1e14c917"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Using tensorboardX\n","Fix size testing.\n","training chunk_sizes: [16]\n","The output will be saved to  /content/FairMOT/src/lib/../../exp/mot/default\n","Setting up data...\n","================================================================================\n","dataset summary\n","OrderedDict([('CrowdHuman_train01', 1.0), ('CrowedHuman_test', 1.0)])\n","total # identities: 3\n","start index\n","OrderedDict([('CrowdHuman_train01', 0), ('CrowedHuman_test', 1.0)])\n","================================================================================\n","heads {'hm': 1, 'wh': 4, 'id': 128, 'reg': 2}\n","Namespace(task='mot', dataset='jde', exp_id='default', test=False, load_model='/content/FairMOT/exp/mot/default/model_last.pth', resume=False, gpus=[0], num_workers=8, not_cuda_benchmark=False, seed=317, print_iter=0, hide_data_time=False, save_all=False, metric='loss', vis_thresh=0.5, arch='yolo', head_conv=256, down_ratio=4, input_res=1088, input_h=1088, input_w=608, lr=0.0001, lr_step=[50], num_epochs=10, batch_size=16, master_batch_size=16, num_iters=-1, val_intervals=5, trainval=False, K=500, not_prefetch_test=False, fix_res=True, keep_res=False, test_mot16=False, val_mot15=False, test_mot15=False, val_mot16=False, test_mot17=False, val_mot17=True, val_mot20=False, test_mot20=False, val_hie=False, test_hie=False, conf_thres=0.4, det_thres=0.3, nms_thres=0.4, track_buffer=30, min_box_area=100, input_video='../videos/MOT16-03.mp4', output_format='video', output_root='../demos', data_cfg='/content/FairMOT/src/lib/cfg/crowdhuman.json', data_dir='/home/zyf/dataset', mse_loss=False, reg_loss='l1', hm_weight=1, off_weight=1, wh_weight=0.1, id_loss='ce', id_weight=1, reid_dim=128, ltrb=True, multi_loss='uncertainty', norm_wh=False, dense_wh=False, cat_spec_wh=False, not_reg_offset=False, gpus_str='0', reg_offset=True, pad=31, num_stacks=1, chunk_sizes=[16], root_dir='/content/FairMOT/src/lib/../..', exp_dir='/content/FairMOT/src/lib/../../exp/mot', save_dir='/content/FairMOT/src/lib/../../exp/mot/default', debug_dir='/content/FairMOT/src/lib/../../exp/mot/default/debug', mean=None, std=None, num_classes=1, output_h=272, output_w=152, output_res=272, heads={'hm': 1, 'wh': 4, 'id': 128, 'reg': 2}, nID=3, img_size=(1088, 608))\n","Creating model...\n","/content/FairMOT/src/lib/models/networks/config/yolov5s.yaml\n","Starting training...\n","loaded /content/FairMOT/exp/mot/default/model_last.pth, epoch 5\n","/usr/local/lib/python3.9/dist-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n","  warnings.warn(warning.format(ret))\n","mot/default |################################| train: [1][235/236]|Tot: 0:05:00 |ETA: 0:00:01 |loss 2.0522 |hm_loss 0.4393 |wh_loss 1.4321 |off_loss 0.2386 |id_loss 0.6429 |Data 0.001s(0.276s) |Net 1.274s \n","mot/default |################################| train: [2][235/236]|Tot: 0:05:05 |ETA: 0:00:01 |loss 1.7322 |hm_loss 0.4053 |wh_loss 1.4182 |off_loss 0.2387 |id_loss 0.5284 |Data 0.001s(0.288s) |Net 1.295s\n","mot/default |################################| train: [3][235/236]|Tot: 0:05:09 |ETA: 0:00:01 |loss 1.5660 |hm_loss 0.3994 |wh_loss 1.3959 |off_loss 0.2389 |id_loss 0.4567 |Data 0.001s(0.278s) |Net 1.312s \n","mot/default |################################| train: [4][235/236]|Tot: 0:04:39 |ETA: 0:00:01 |loss 1.2968 |hm_loss 0.3539 |wh_loss 1.3373 |off_loss 0.2357 |id_loss 0.4057 |Data 0.002s(0.203s) |Net 1.184s\n","mot/default |################################| train: [5][235/236]|Tot: 0:04:34 |ETA: 0:00:01 |loss 1.1810 |hm_loss 0.3411 |wh_loss 1.3702 |off_loss 0.2340 |id_loss 0.3683 |Data 0.001s(0.193s) |Net 1.162s \n","mot/default |################################| train: [6][235/236]|Tot: 0:04:34 |ETA: 0:00:01 |loss 1.1825 |hm_loss 0.3667 |wh_loss 1.3591 |off_loss 0.2355 |id_loss 0.3384 |Data 0.001s(0.177s) |Net 1.164s \n","mot/default |################################| train: [7][235/236]|Tot: 0:04:32 |ETA: 0:00:01 |loss 1.0591 |hm_loss 0.3511 |wh_loss 1.3326 |off_loss 0.2330 |id_loss 0.3143 |Data 0.001s(0.177s) |Net 1.156s \n","mot/default |################################| train: [8][235/236]|Tot: 0:04:29 |ETA: 0:00:01 |loss 0.9396 |hm_loss 0.3294 |wh_loss 1.3196 |off_loss 0.2345 |id_loss 0.2918 |Data 0.001s(0.164s) |Net 1.141s \n","mot/default |################################| train: [9][235/236]|Tot: 0:04:29 |ETA: 0:00:01 |loss 0.8597 |hm_loss 0.3222 |wh_loss 1.3187 |off_loss 0.2343 |id_loss 0.2689 |Data 0.001s(0.166s) |Net 1.141s\n","mot/default |################################| train: [10][235/236]|Tot: 0:04:30 |ETA: 0:00:01 |loss 0.8048 |hm_loss 0.3274 |wh_loss 1.2999 |off_loss 0.2323 |id_loss 0.2472 |Data 0.001s(0.160s) |Net 1.144s\n","\u001b[?25h"]}]},{"cell_type":"code","source":["\n","# Дообучаем 35+ 5epoch\n","!python /content/FairMOT/src/train.py mot --arch 'yolo' --gpus 0 --load_model /content/FairMOT/exp/mot/default/model_last.pth  --batch_size 16  --num_epochs 5 --lr_step '50' --data_cfg '/content/FairMOT/src/lib/cfg/crowdhuman.json'\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QDAfVe7bmdml","outputId":"39c6063d-0fac-4b52-a08c-b7653f7034f8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Using tensorboardX\n","Fix size testing.\n","training chunk_sizes: [16]\n","The output will be saved to  /content/FairMOT/src/lib/../../exp/mot/default\n","Setting up data...\n","================================================================================\n","dataset summary\n","OrderedDict([('CrowdHuman_train01', 1.0), ('CrowedHuman_test', 1.0)])\n","total # identities: 3\n","start index\n","OrderedDict([('CrowdHuman_train01', 0), ('CrowedHuman_test', 1.0)])\n","================================================================================\n","heads {'hm': 1, 'wh': 4, 'id': 128, 'reg': 2}\n","Namespace(task='mot', dataset='jde', exp_id='default', test=False, load_model='/content/FairMOT/exp/mot/default/model_last.pth', resume=False, gpus=[0], num_workers=8, not_cuda_benchmark=False, seed=317, print_iter=0, hide_data_time=False, save_all=False, metric='loss', vis_thresh=0.5, arch='yolo', head_conv=256, down_ratio=4, input_res=1088, input_h=1088, input_w=608, lr=0.0001, lr_step=[50], num_epochs=5, batch_size=16, master_batch_size=16, num_iters=-1, val_intervals=5, trainval=False, K=500, not_prefetch_test=False, fix_res=True, keep_res=False, test_mot16=False, val_mot15=False, test_mot15=False, val_mot16=False, test_mot17=False, val_mot17=True, val_mot20=False, test_mot20=False, val_hie=False, test_hie=False, conf_thres=0.4, det_thres=0.3, nms_thres=0.4, track_buffer=30, min_box_area=100, input_video='../videos/MOT16-03.mp4', output_format='video', output_root='../demos', data_cfg='/content/FairMOT/src/lib/cfg/crowdhuman.json', data_dir='/home/zyf/dataset', mse_loss=False, reg_loss='l1', hm_weight=1, off_weight=1, wh_weight=0.1, id_loss='ce', id_weight=1, reid_dim=128, ltrb=True, multi_loss='uncertainty', norm_wh=False, dense_wh=False, cat_spec_wh=False, not_reg_offset=False, gpus_str='0', reg_offset=True, pad=31, num_stacks=1, chunk_sizes=[16], root_dir='/content/FairMOT/src/lib/../..', exp_dir='/content/FairMOT/src/lib/../../exp/mot', save_dir='/content/FairMOT/src/lib/../../exp/mot/default', debug_dir='/content/FairMOT/src/lib/../../exp/mot/default/debug', mean=None, std=None, num_classes=1, output_h=272, output_w=152, output_res=272, heads={'hm': 1, 'wh': 4, 'id': 128, 'reg': 2}, nID=3, img_size=(1088, 608))\n","Creating model...\n","/content/FairMOT/src/lib/models/networks/config/yolov5s.yaml\n","Starting training...\n","loaded /content/FairMOT/exp/mot/default/model_last.pth, epoch 10\n","/usr/local/lib/python3.9/dist-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n","  warnings.warn(warning.format(ret))\n","mot/default |################################| train: [1][235/236]|Tot: 0:04:31 |ETA: 0:00:02 |loss 1.5093 |hm_loss 0.2924 |wh_loss 1.3284 |off_loss 0.2361 |id_loss 0.6144 |Data 0.001s(0.182s) |Net 1.150s \n","mot/default |################################| train: [2][235/236]|Tot: 0:04:33 |ETA: 0:00:01 |loss 1.1608 |hm_loss 0.2527 |wh_loss 1.2929 |off_loss 0.2357 |id_loss 0.4891 |Data 0.001s(0.206s) |Net 1.157s \n","mot/default |################################| train: [3][235/236]|Tot: 0:04:35 |ETA: 0:00:01 |loss 1.0183 |hm_loss 0.2571 |wh_loss 1.2517 |off_loss 0.2348 |id_loss 0.4098 |Data 0.001s(0.188s) |Net 1.168s\n","mot/default |################################| train: [4][235/236]|Tot: 0:04:35 |ETA: 0:00:01 |loss 0.8225 |hm_loss 0.2324 |wh_loss 1.2218 |off_loss 0.2321 |id_loss 0.3530 |Data 0.001s(0.196s) |Net 1.167s \n","mot/default |################################| train: [5][235/236]|Tot: 0:04:36 |ETA: 0:00:01 |loss 0.8317 |hm_loss 0.2564 |wh_loss 1.3060 |off_loss 0.2329 |id_loss 0.3086 |Data 0.001s(0.188s) |Net 1.172s \n","\u001b[?25h"]}]},{"cell_type":"code","source":["\n","# Дообучаем 40+ 10epoch\n","!python /content/FairMOT/src/train.py mot --arch 'yolo' --gpus 0 --load_model /content/FairMOT/exp/mot/default/model_last.pth  --batch_size 16  --num_epochs 10 --lr_step '5' --data_cfg '/content/FairMOT/src/lib/cfg/crowdhuman.json'\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aNoAdoRqmdi8","outputId":"111cd8fd-6c3c-4d8d-c4f7-fb13eb891a2c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Using tensorboardX\n","Fix size testing.\n","training chunk_sizes: [16]\n","The output will be saved to  /content/FairMOT/src/lib/../../exp/mot/default\n","Setting up data...\n","================================================================================\n","dataset summary\n","OrderedDict([('CrowdHuman_train01', 1.0), ('CrowedHuman_test', 1.0)])\n","total # identities: 3\n","start index\n","OrderedDict([('CrowdHuman_train01', 0), ('CrowedHuman_test', 1.0)])\n","================================================================================\n","heads {'hm': 1, 'wh': 4, 'id': 128, 'reg': 2}\n","Namespace(task='mot', dataset='jde', exp_id='default', test=False, load_model='/content/FairMOT/exp/mot/default/model_last.pth', resume=False, gpus=[0], num_workers=8, not_cuda_benchmark=False, seed=317, print_iter=0, hide_data_time=False, save_all=False, metric='loss', vis_thresh=0.5, arch='yolo', head_conv=256, down_ratio=4, input_res=1088, input_h=1088, input_w=608, lr=0.0001, lr_step=[5], num_epochs=10, batch_size=16, master_batch_size=16, num_iters=-1, val_intervals=5, trainval=False, K=500, not_prefetch_test=False, fix_res=True, keep_res=False, test_mot16=False, val_mot15=False, test_mot15=False, val_mot16=False, test_mot17=False, val_mot17=True, val_mot20=False, test_mot20=False, val_hie=False, test_hie=False, conf_thres=0.4, det_thres=0.3, nms_thres=0.4, track_buffer=30, min_box_area=100, input_video='../videos/MOT16-03.mp4', output_format='video', output_root='../demos', data_cfg='/content/FairMOT/src/lib/cfg/crowdhuman.json', data_dir='/home/zyf/dataset', mse_loss=False, reg_loss='l1', hm_weight=1, off_weight=1, wh_weight=0.1, id_loss='ce', id_weight=1, reid_dim=128, ltrb=True, multi_loss='uncertainty', norm_wh=False, dense_wh=False, cat_spec_wh=False, not_reg_offset=False, gpus_str='0', reg_offset=True, pad=31, num_stacks=1, chunk_sizes=[16], root_dir='/content/FairMOT/src/lib/../..', exp_dir='/content/FairMOT/src/lib/../../exp/mot', save_dir='/content/FairMOT/src/lib/../../exp/mot/default', debug_dir='/content/FairMOT/src/lib/../../exp/mot/default/debug', mean=None, std=None, num_classes=1, output_h=272, output_w=152, output_res=272, heads={'hm': 1, 'wh': 4, 'id': 128, 'reg': 2}, nID=3, img_size=(1088, 608))\n","Creating model...\n","/content/FairMOT/src/lib/models/networks/config/yolov5s.yaml\n","Starting training...\n","loaded /content/FairMOT/exp/mot/default/model_last.pth, epoch 5\n","/usr/local/lib/python3.9/dist-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n","  warnings.warn(warning.format(ret))\n","mot/default |################################| train: [1][235/236]|Tot: 0:04:36 |ETA: 0:00:01 |loss 1.1948 |hm_loss 0.2088 |wh_loss 1.2357 |off_loss 0.2334 |id_loss 0.6042 |Data 0.002s(0.180s) |Net 1.170s\n","mot/default |############                    | train: [2][90/236]|Tot: 0:01:56 |ETA: 0:03:15 |loss 0.9492 |hm_loss 0.1851 |wh_loss 1.1943 |off_loss 0.2319 |id_loss 0.5106 |Data 0.011s(0.278s) |Net 1.275s"]}]},{"cell_type":"code","source":["# скачиваем последние веса модели\n","\n","from google.colab import files\n","files.download('/content/FairMOT/exp/mot/default/model_last.pth')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"id":"f6EfzNIwxWaB","outputId":"3f331449-803d-481d-d3a6-9b144a5a5667"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_0fd39237-29ca-403f-8c94-0e1739d56e8f\", \"model_last.pth\", 60508113)"]},"metadata":{}}]},{"cell_type":"markdown","source":["## **Если на следующий день**"],"metadata":{"id":"ZiuIO-cwmmGU"}},{"cell_type":"code","source":["# Загружаем предыдущую модель  /content/model_last.pth\n","!gdown --no-cookies --fuzzy https://cloud.mail.ru/public/9iam/ZSsgVsSdb"],"metadata":{"id":"Y3EQfQM3dzyV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Дообучаем\n","!python /content/FairMOT/src/train.py mot --arch 'yolo' --gpus 0 --load_model /content/model_last.pth  --batch_size 16  --num_epochs 5 --lr_step '50' --data_cfg '/content/FairMOT/src/lib/cfg/crowdhuman.json'"],"metadata":{"id":"Bm6rO42G-Ola"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%cd /content/FairMOT/src\n","!python demo.py mot --arch resdcn_34 --load_model /content/FairMOT/exp/mot/default/model_last.pth --conf_thres 0.4 --input-video /content/my_video.wmv "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sBl3jTo9zRRW","outputId":"cef2565b-bdf5-480b-d063-a1989d21dc7c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/FairMOT/src\n","Fix size testing.\n","training chunk_sizes: [6, 6]\n","The output will be saved to  /content/FairMOT/src/lib/../../exp/mot/default\n","heads {'hm': 1, 'wh': 4, 'id': 128, 'reg': 2}\n","2023-01-25 18:45:17 [INFO]: Starting tracking...\n","[ERROR:0@4.495] global /io/opencv/modules/videoio/src/cap.cpp (164) open VIDEOIO(CV_IMAGES): raised OpenCV exception:\n","\n","OpenCV(4.6.0) /io/opencv/modules/videoio/src/cap_images.cpp:253: error: (-5:Bad argument) CAP_IMAGES: can't find starting number (in the name of file): /content/my_video.wmv in function 'icvExtractPattern'\n","\n","\n","Lenth of the video: 0 frames\n","Creating model...\n","=> loading pretrained model https://download.pytorch.org/models/resnet34-333f7ec4.pth\n","=> init deconv weights from normal distribution\n","loaded /content/FairMOT/exp/mot/default/model_last.pth, epoch 3\n","2023-01-25 18:45:24 [INFO]: save results to ../demos/results.txt\n","ffmpeg version 4.2.7-0ubuntu0.1 Copyright (c) 2000-2022 the FFmpeg developers\n","  built with gcc 9 (Ubuntu 9.4.0-1ubuntu1~20.04.1)\n","  configuration: --prefix=/usr --extra-version=0ubuntu0.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-avresample --disable-filter=resample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librsvg --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-nvenc --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n","  libavutil      56. 31.100 / 56. 31.100\n","  libavcodec     58. 54.100 / 58. 54.100\n","  libavformat    58. 29.100 / 58. 29.100\n","  libavdevice    58.  8.100 / 58.  8.100\n","  libavfilter     7. 57.100 /  7. 57.100\n","  libavresample   4.  0.  0 /  4.  0.  0\n","  libswscale      5.  5.100 /  5.  5.100\n","  libswresample   3.  5.100 /  3.  5.100\n","  libpostproc    55.  5.100 / 55.  5.100\n","\u001b[0;35m[image2 @ 0x5556fe286000] \u001b[0m\u001b[1;31mCould find no file with path '../demos/frame/%05d.jpg' and index in the range 0-4\n","\u001b[0m\u001b[1;31m../demos/frame/%05d.jpg: No such file or directory\n","\u001b[0m"]}]}]}